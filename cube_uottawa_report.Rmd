---
title: "CUBE - UOttawa"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    theme: spacelab
    highlight: kate
---

Manuscript draft (google doc) available here:   https://docs.google.com/document/d/15joiEhDGsYJTgS0y5KkjgVT_Usv1emeCA80fxc0Odkk/edit?usp=sharing

----

## Renamed Sites

Anonymized building codes:

- RES = 90U (university residence)
- LIB = MRT (library)
- GYM = MNT (sports facility and lecture halls)
- ADM1 = TBT (central administration, info-services, lecture halls)
- ADM2 = LPR (campus protection, postal services)
- FAC = DMS (school of management, conference spaces, classrooms, offices)


----

<details>
<summary>Analysis code</summary>

```{r setup, echo=F}
knitr::opts_chunk$set(
  echo = T, message = F, warning = F, fig.align = 'center'
  )
```

```{r data analysis, echo=TRUE}
# setup ---------------------------------------------
library(tidyverse)
library(here)
library(ggiraph)
library(patchwork)
library(ggtext)
library(janitor)
set.seed(123)

ggplot2::theme_set(theme_bw() + theme(
  legend.text = element_markdown(family = 'IBM Plex Sans', colour = 'gray30'),
  axis.text = element_markdown(family = 'IBM Plex Sans', colour = 'gray30'),
  axis.title = element_markdown(family = 'IBM Plex Sans',colour = 'gray30'),
))
hrbrthemes::import_plex_sans()

source(here('R/report_plots.R'))

# Functions -----------------------------------------

convert_cq_to_copies <- function(cq) 10 ** ((40.1 - cq) / 3.23)

# creates yyyy-ww label for grouping data
get_date_week <- function(x){
  y <- lubridate::year(x)
  w <- lubridate::week(x) |> str_pad(2, 'left', 0)
  str_glue("{y}-{w}")
}

# reverses get_date_week to Weds date during week
week_to_date <- function(year_week){
  year <- str_extract(year_week, '^....')
  d <- str_glue('{year}-01-01') |> as_date()
  wk <- str_extract(year_week, '..$') |> as.integer()
  ydays <- if_else(
    year == '2021',
    days(7*wk - 2),
    days(7*wk - 3),
  )
  return(d + ydays)
}


# get biweekly bin date for vector of dates
get_date_biweekly <- function(x){
  day_of_week <-  lubridate::wday(x)
  case_when(
    day_of_week %in% 1:3 ~ x + 2 - day_of_week,
    TRUE ~ x + 5 - day_of_week,
  )
}

# dates 2021-2022 with biweekly groups
biweekly_date_sequence <- function(){
  tibble(
    date = seq(
      as_date('2021-01-01'), 
      as_date('2022-12-31'), 
      by = 1)
  ) |> 
    mutate(biweek = get_date_biweekly(date))
}

# lookup table for date
week_midpoint_date_lookup <- function(start = '2021-01-01', end = '2023-01-01'){
  ends = lubridate::as_date(c(start, end))
  tibble(
    date = seq(ends[1], ends[2], by = 1),
    date_week = lubridate::week(date) |> str_pad(2, 'left', '0'),
    date_year = lubridate::year(date),
    week = str_glue("{date_year}-{date_week}"),
  ) |> 
    group_by(week) |> 
    summarise(date = mean(date))
}

# convert site1/site2 to hi/low traffic
get_traffic_level <- function(location){
  if_else(
    str_detect(location, 'Site 1'), 
    'high traffic', 
    'low traffic'
  )
} 

binom_ci <- function(x, n){
  Hmisc::binconf(x, n, method = 'wilson', alpha = 0.05) |> 
    as_tibble() |> 
    janitor::clean_names()
}

get_binom_ci <- function(data){
  data |> 
    summarise(
      x = sum(pcr_positive == 'Positive'),
      n = n(),
      binconf = map2(x, n, ~binom_ci(.x, .y))
    ) |> 
    unnest(binconf) |> 
    mutate(across(c(point_est, lower, upper), ~(.x*100) |> round(1)))
}

# Plot Elements ---------------------------------------

theme_color <- 'cornflowerblue'

# layout x-axis
scale_x_study_dates <- function(){
    scale_x_date(
      date_breaks = 'month',
      date_labels = month.name[c(9:12, 1:5)] |> strtrim(3) |> 
        paste0(' ', c(rep(2021, 4), rep(2022, 5))),
      limits = c(
        min(swabs_tidy$date_swab), 
        max(swabs_tidy$date_swab)
      ))
}

scale_x_date_month <- function(){
    scale_x_date(
      date_breaks = 'month',
      date_labels = month.name[c(9:12, 1:5)] |> strtrim(1),
      limits = c(
        min(swabs_tidy$date_swab), 
        max(swabs_tidy$date_swab)
      ))
}

# get rid of x-axis for vertically stacked plots
theme_no_x_labels <- function(){
  theme(
    axis.ticks.x = element_blank(),
    axis.title.x = element_blank(),
    axis.text.x = element_blank()
  )
}

# get rid of y-axis for horizontally stacked plots
theme_no_y_labels <- function(){
  theme(
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank()
  )
}

# no minor grid and adjust spacing for multipanel
theme_remove_grid <- function(){
  theme(
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title.position = 'panel', 
    plot.title = element_markdown(
      vjust = -1, 
      size = 8, 
      face = 'bold', 
      family = 'IBM Plex Sans',
      colour = 'gray50',
      margin = margin(0, 0, 0, 0)),
    plot.margin = unit(c(0, 0, 0, 0), 'mm'))
}

# Data ------------------------------------------------

# Lookup for anonymized building names
lookup_swab_sites <- lst(
  '90U' = 'RES',
  MRT = 'LIB',
  MNT = 'GYM',
  TBT = 'ADM1',
  LPR = 'ADM2',
  DMS = 'FAC'
)

# swab data
swabs <- 
  read_rds(here('data/cube.rds')) |> 
  filter(str_detect(site, '^UO_')) |> 
  mutate(site = str_remove(site, 'UO_'))

# filtered swabs without controls or sponge samples
swabs_tidy <- 
  swabs |> 
  filter(
    !negative_control, 
    swab_type != 'sponge',
    date_swab < '2022-04-27'
  ) |> 
  select(date_swab, site, floor, location, pcr_positive, pcr_ct, co2) |> 
  mutate(
    biweek = get_date_biweekly(date_swab),
    site = map_chr(site, ~lookup_swab_sites[[.]])
  )

# ottawa wastewater data: daily means
regional_ww <- 
  read_rds(here('data/ww_ottawa.rds')) |> 
  select(sample_date, starts_with('cov_')) |> 
  pivot_longer(contains('cov_')) |> 
  mutate(target = str_extract(name, 'cov_n.'),
         stat = str_extract(name, 'mean|sd'),
         ) |> 
  select(-name) |> 
  pivot_wider(names_from = stat, values_from = value) |> 
  mutate(.lower = mean - sd, .upper = mean + sd)   

# wifi data from university of ottawa
wifi <- 
  read_rds(here('data/uo_wifi.rds')) |> 
  filter(date >= min(swabs$date_swab) - 2, 
         date <= max(swabs$date_swab) + 2) |> 
  mutate(biweek = get_date_biweekly(date),
         site = map_chr(site, ~lookup_swab_sites[[.]]))

# important dates for context
event_dates <- 
  tribble(
    ~event, ~start, ~end,
    'Reading Week',  '2021-10-24', '2021-10-30',
    'Holiday Break', '2021-12-22', '2022-01-04',
    'Closure',       '2022-01-04', '2022-01-31',
    'Closure',       '2022-02-16', '2022-02-21',
    'Reading Week',  '2022-02-20', '2022-02-26',
  ) |> 
  mutate(across(start:end, as_date))

# UOttawa cases data
# clean data from: source(here('R/01_impute_missing_case_dates.R'))
cases <-
  read_rds(here('data/cases_rule_imputed.rds')) |> 
  select(-c(symptoms_began, tested, positive_result, isolation_end, 
            confirmed_by_test)) |>
  set_names(c('case', 'role', 'RES', 'FAC', 'ADM2', 'GYM', 'LIB', 'ADM1', 'case_date')) |> 
  mutate(biweek = get_date_biweekly(case_date)) |> 
  nest(associated_sites = RES:ADM1)


total_n_cases_study_period <- 
  cases |> 
  filter(case_date > '2021-09-20') |> 
  nrow()


# Summaries -----------------------------------------
# 
positivity_summary <- function(swabs){
  swabs |> 
    summarise(
      n = n(),
      x = sum(pcr_positive == 'Positive', na.rm = F),
      positivity = round(100 * x / n, digits = 1),
      .groups = 'drop')
}

co2_summary <- function(swabs){
  swabs |> 
    summarise(
      n = n(),
      co2_vals = list(co2),
      co2_mean = mean(co2, na.rm = T),
      .groups = 'drop')
}
  
# overall summary
swab_summary <- swabs_tidy |> positivity_summary()

# site summary
swab_summary_sites <- swabs_tidy |> 
  group_by(site) |> 
  positivity_summary()
  
# high-low traffic summary
swab_summary_location_traffic <- 
  swabs_tidy |> 
  mutate(traffic = get_traffic_level(location)) |> 
  group_by(traffic) |> 
  positivity_summary()

## Figure 1: data aggregation --------------------------

# uottawa cases - biweekly counts 
cases_biweekly <- 
  cases |> 
  select(case, biweek, role) |> 
  group_by(biweek) |> 
  summarise(cases = n(),
            cases_student = sum(role == 'Student'),
            cases_staff = sum(role == 'Employee'),
            ) |> 
  right_join(
    biweekly_date_sequence() |> 
      filter(biweek < '2022-02-03') |> 
      distinct(biweek),
    by = 'biweek'
  ) |> 
  mutate(across(where(is.integer), ~if_else(is.na(.), 0L, .))) 

# swabs biweekly summary
swabs_biweekly <- 
  swabs_tidy |>
  group_by(biweek) |> 
  positivity_summary() |> 
  left_join(swabs_tidy |> group_by(biweek) |> co2_summary(),
            by = join_by(biweek, n))

# swabs biweekly summary by site  
swabs_biweekly_by_site <- 
  swabs_tidy |>
  group_by(site, biweek) |> 
  positivity_summary() |> 
  left_join(
    swabs_tidy |> group_by(site, biweek) |> co2_summary(),
    by = join_by(site, biweek, n)
  )

# daily regional ww data for study period
regional_ww_daily <- 
  regional_ww |> 
  filter(
    sample_date >= min(swabs_tidy$date_swab) - 4,
    sample_date <= max(swabs_tidy$date_swab) + 4,
  ) |> 
  group_by(sample_date) |> 
  summarise(mean = mean(mean, na.rm = T))

# regional ww biweekly means
regional_ww_biweekly <- 
  regional_ww_daily |> 
  mutate(biweek = get_date_biweekly(sample_date)) |> 
  group_by(biweek) |> 
  summarise(mean = mean(mean))

# overall wifi biweekly timeseries
wifi_biweekly <- 
  wifi |> 
  group_by(biweek) |> 
  summarise(
    n = n(),
    min = min(clients, na.rm = T),
    mean = mean(clients, na.rm = T),
    max = max(clients, na.rm = T)
  )

# per building wifi biweekly timeseries
wifi_biweek_sites <- 
  wifi |> 
  group_by(biweek, site) |> 
  summarise(
    n = n(),
    min = min(clients, na.rm = T),
    mean = mean(clients, na.rm = T),
    max = max(clients, na.rm = T),
    .groups = 'drop'
  )

# Map --------------------------------------------------

swab_coords <- tribble(
  ~site, ~name, ~lat, ~lng,
  'MRT', 'Morrisette Hall (MRT)', 45.4232391, -75.684289,
  'MNT', 'Montpetit', 45.4225417102, -75.6826587146,
  '90U', '90 University', 45.422425557, -75.68501449,
  'DMS', 'Desmarais Bldg.', 45.4238767934, -75.687270754,
  'TBT', 'Tabaret Hall', 45.4245094016, -75.6863190018,
  'LPR',  'Louis Pasteur Bldg.', 45.42137566861, -75.6802638999,
)

figure_sites_map <- 
  leaflet::leaflet(swab_coords, width = '300px', height = '300px') |> 
  leaflet::addProviderTiles(
    leaflet::providers$CartoDB.Positron
  ) |> 
  leaflet::setView(lng = -75.6843, lat = 45.4235, zoom = 14) |> 
  leaflet::addCircleMarkers(
    ~lng, ~lat, 
    label = ~name, 
    popup = ~name, 
    radius = 2, 
    color = '#440099'
    ) |> 
  leaflet::addLabelOnlyMarkers(
    ~lng, ~lat, 
    label =  ~site, 
    labelOptions = leaflet::labelOptions(
      noHide = T, direction = 'top', textOnly = T, 
    )) |> 
  leaflet::addCircleMarkers(
    ~lng, 
    ~lat,
    label = ~site, 
    radius = 2,
    color = '#440099'
    ) 

# Results ----------------------------------------------------

## corr -----

# joining data for pairwise correlations
biweekly_data <-  lst(
  swab_co2 = swabs_biweekly |> 
    transmute(biweek, `Swab PCR` = positivity, `CO2` = co2_mean),
  wifi = wifi_biweekly |> transmute(biweek, `Wi-Fi` = mean),
  ww = regional_ww_biweekly |> transmute(biweek, `Ottawa WW` = mean),
  cases = cases_biweekly |> transmute(biweek, Cases = cases),
) |> 
  reduce(left_join, by = 'biweek')

corr_spearman <- biweekly_data |> 
  select(-biweek) |> 
  corrr::correlate(use = 'pairwise.complete.obs',
                   method = 'spearman')

# to get pvalues...
corrtest <- 
  biweekly_data |> 
  select(-biweek) |> 
  psych::corr.test(
    use = 'pairwise',
    method = 'spearman',
    adjust = 'none' # See p.adjust for "holm" > "bonferroni").
  )

# spearman r and p-values; upper triangle has adj. correlations
corr_r <- corrtest$r |> round(3)
corr_p <- corrtest$p |> round(3)

# remove lower tri with raw probabilities
corr_r[lower.tri(corr_r, diag = T)] <- NA
corr_p[lower.tri(corr_p, diag = T)] <- NA

corr_tbl_r <- kableExtra::kable(
  x = corr_r,
  format = 'pipe',
  caption = 'Campus-wide, biweekly metrics: Spearman r'
)
corr_tbl_p <- kableExtra::kable(
  x = corr_p,
  format = 'pipe',
  caption = 'Campus-wide, biweekly metrics: p-value on Spearman r'
)

corr_ci <- corrtest |> 
  pluck('ci') |>
  as_tibble() |> 
  mutate(terms = rownames(corrtest$ci), .before = 1L)

rm(corr_r, corr_p, corrtest)
```

</details>


--------------------------------------------

<br>

## Models

- **Hypothesis testing**. *H~A~*: swab-PCR positivity, CO~2~, wifi, and WW signals are  predictive of number of cases. *H~0~*: no relationship.
- **Method**: Backwards selection of significant predictors, ANOVA  
- **Formula**: `cases ~ swab_pcr + co2 + wifi + regional_ww + (all interactions...)`. 
- Data: 29 complete observations
   - `cases` counted only until Feb 2022 (~40% miss).  
   - `wifi` occasional missing data. 
- We standardized our predictors such that we would get standardize effects, since we are mostly interested in comparing different predictors within a model, as opposed to comparing estimates across different data sets.
- We did not consider interactions because of the limited size of our dataset

<br>

```{r model data, fig.height=5, fig.width=5, fig.align='center'}
# n=31 biweekly obs with cases
df_mod <- biweekly_data |> 
  janitor::clean_names() |> 
  filter(!is.na(cases)) |> 
  mutate(across(
    -c(cases, biweek), ~as.numeric(scale(.))
  ))

# only 29 complete observations, oof
df_mod_complete_obs <- df_mod |> na.omit()

# missing data
naniar::vis_miss(df_mod) +
  labs(subtitle = 'Aggregated TS Missingness')
```

<br>

--------------------------------------------


<details>
<summary>Case count distribution</summary>

**Cases counts** seem to follow a negative binomial distribution a bit more than a Poisson. There is maybe some zero-inflation in our cases variable.

```{r cases distribution, fig.height=5, fig.width=5}
# simulated curves
add_poisson_density_curve <- function(p) {
  p + geom_density(
    data = tibble(
      x = rpois(n = sum(!is.na(df_mod$cases)),
                lambda = mean(df_mod$cases, na.rm = T))
      ), 
    aes(x), color = 'blue', alpha = 0.25, linewidth = 0.03
  )
}
add_nb_density_curve <- function(p) {
  p +     
    geom_density(
      data = tibble(x = rnbinom(
        size = 1,
        n = sum(!is.na(df_mod$cases)),
        mu = mean(df_mod$cases, na.rm = T),
      )), 
      aes(x), color = 'blue', alpha = 0.25, linewidth = 0.03
    )
}
simulation_plot <- function(plt_fn, title){
  p <- df_mod |> ggplot()
  walk(seq(100), ~ {p <<- plt_fn(p)})
  p + 
    geom_density(aes(cases)) + 
    labs(x = 'Cases', subtitle = title)
}

# Poisson dist
p1 <- simulation_plot(
  add_poisson_density_curve,
  'Cases vs. Simulated poisson distribution'
  )

# NB dist
p2 <- simulation_plot(
  add_nb_density_curve,
  'Cases vs. Simulated negative binomial distribution'
  )

(p1 / p2)

rm(p1, p2, add_poisson_density_curve, add_nb_density_curve)
```

<br>

--------------------------------------------

</details>

### Poisson Regression, Backwards Selection

<br>

```{r model summary functions}
coefficients_table <- function(model, caption) {
  model |> 
    broom::tidy(conf.int = T, conf.level = 0.95) |> 
    mutate(across(where(is.double), ~round(., 4))) |> 
    kableExtra::kable(
      format = 'pipe',
      caption = caption
    )
  }

incidence_ratio_table <- function(model, caption) {
  model |> 
    broom::tidy(exponentiate = T, conf.int = T, conf.level = 0.95) |> 
  mutate(across(where(is.double), ~round(., 4))) |> 
  kableExtra::kable(
    format = 'pipe',
    caption = caption
    )
}

anova_table <- function(model, type, caption){
  model |> 
    car::Anova(type = type) |> 
    rownames_to_column(var = 'Term') |> 
    as_tibble() |> 
    kableExtra::kable(
      format = 'pipe',
      caption = caption
    )
}
```


--------------------------------------------

#### Poisson Main Effects Only

Poisson model chosen by backward elimination with no interactions identifies swab positivity, Ottawa WW signal, and wifi as significant predictors. CO2 is the only main effect dropped from the full model during backward elimination.


```{r}
# poission reg, full model, main effects only
mod_pois_main_eff <- glm(
  cases ~ .,
  data = df_mod_complete_obs |> select(-biweek), 
  family = 'poisson'
  )

# we computed generalized variance-inflation factors (with car::vif) to examine mu
# ottawa_ww has high collinearity
# violates the assumption of ...
# coefficients could be highly sensitive to changes in the model
car::vif(mod_pois_main_eff)


mod_pois_main_eff_stepwise <- step(mod_pois_main_eff, trace = T)
stopifnot(mod_pois_main_eff_stepwise$converged)

# nearly significant overdispersion when only main effects included
AER::dispersiontest(mod_pois_main_eff_stepwise)

# regression coefs and 95%CI
mod_pois_main_eff_stepwise |> coefficients_table(
  caption = "Poisson regression summary: coefficients & 95% CI for model selected by backward elimination"
)

# incidence ratios
mod_pois_main_eff_stepwise |> incidence_ratio_table(
  caption = "Poisson model summary: Incidence ratios & 95% CI for model selected by backward elimination"
)

# type II SS test
mod_pois_main_eff_stepwise |> anova_table(type = 2, caption = "Type II ANOVA")
    
```

<details>
<summary>***Backward selection model summary and diagnostics***</summary>
```{r}
summary(mod_pois_main_eff_stepwise)
hist(mod_pois_main_eff_stepwise$residuals)
# plot(mod_pois_main_eff_stepwise)
rm(mod_pois_main_eff)
```
</details>
<br>

--------------------------------------------


### Model for High v Low Traffic

To evaluate whether high traffic locations are different from low traffic sites, in terms of swab-PCR positivity, we fit a mixed model with random intercepts for different sites. There was slightly greater swab positivity at high traffic sites (15%) than low traffic sites (12%). Our model indicates that the effect is small and non-significant; high-traffic sites had an OR of 1.28 (95% CI 0.77, 2.13) compared to low-traffic sites. 

```{r}
# traffic-level effect modelling
traffic_swabs <- 
  swabs_tidy |> 
  mutate(
    traffic = get_traffic_level(location) |> 
      str_remove('\\straffic') |> 
      factor(levels = c('low', 'high'))
    ) |> 
  select(site, traffic, pcr_positive)

traffic_model <- 
  lme4::glmer(
    pcr_positive ~ traffic + (1 | site), 
    data = traffic_swabs,
    family = 'binomial'
  ) |> 
  broom.mixed::tidy(conf.int = T, exponentiate = T) |> 
  mutate(across(where(is.double), ~round(., 2)))
  
# positivity results
swab_summary_location_traffic |> 
  set_names(c('Traffic level', 'N', 'PCR-Positive', '%')) |> 
  kableExtra::kable(
    format = 'pipe',
    caption = 'Positivity by sample location traffic-level'
  )
# mixed model res table
traffic_model |> 
  kableExtra::kable(
    format = 'pipe',
    caption = 'Traffic level - Random intercepts model'
  )

```


--------------------------------------------


### Model for Cases w/in buildings

To model case counts at the building level, we
fit a Poisson regression with a random intercept for each site, using the quantity of SARS-CoV-2 RNA recovered by PCR as a predictor. For this model, our predictor was the log-transformed mean number of viral copies (plus one) per-building during weekly intervals. Thus our model formula was: $cases \sim log10(copies + 1) + (1 | site)$

Generalized linear mixed model was fit by maximum likelihood using the 'lme4' function from the 'glmer' package. From the fitted model, we computed incidence ratios and Wald-type 95% CIs.


```{r}
# group swabs by week & site
bldg_swabs <- 
  swabs_tidy |> 
  filter(date_swab < '2022-02-02') |> 
  mutate(
    week = get_date_week(date_swab) |> as.character(),
    copies = convert_cq_to_copies(pcr_ct),
    copies_plus_one = if_else(
      is.na(copies), 1, copies + 1
      )
  ) |>
  group_by(site, week) |> 
  summarise(
    copies_plus_one = 10 ** mean(log10(copies_plus_one),
                        na.rm = T),
    positivity = sum(pcr_positive == 'Positive') / n(),
    .groups = 'drop') |> 
  mutate(week = week_to_date(week))

# 72 cases associated with study bldgs (at least one)
bldg_cases <- 
  cases |> 
  filter(case_date > '2021-09-20') |> 
  unnest(associated_sites) |> 
  pivot_longer(RES:ADM1, names_to = 'site') |> 
  filter(value) |> 
  select(-value, -biweek, -case) |> 
  mutate(week = get_date_week(case_date)) |> 
  group_by(week, site) |> 
  summarise(cases = n(), .groups = 'drop') |> 
  mutate(week = week_to_date(week))

bldg_df <- bldg_swabs |> 
  left_join(bldg_cases, by = join_by(site, week)) |> 
  mutate(cases = if_else(is.na(cases), 0, cases))

rm(bldg_cases, bldg_swabs)

# fit model
bldg_model <- lme4::glmer(
  cases ~ log10(copies_plus_one) + (1|site),
  data = bldg_df,
  family = 'poisson'
)

broom.mixed::glance(bldg_model)

# coefs
broom.mixed::tidy(
  bldg_model, 
  conf.int = T, 
  exponentiate = F,
  conf.level = 0.95,
  conf.method = "Wald")


# Wald-type CIs
bldg_model_summary <- 
  broom.mixed::tidy(
    bldg_model, 
    conf.int = T, 
    exponentiate = T,
    conf.level = 0.95,
    conf.method = "Wald")

print(bldg_model_summary)

# exponentiate doesn't work on random values..
bldg_model_intercepts <- 
  broom.mixed::tidy(
    bldg_model, 
    effects = 'ran_vals', 
    exponentiate = F,
    conf.int = T, 
    conf.level = 0.95
  ) |> 
  # convert coefs to IRs
  mutate(across(c(estimate, conf.low, conf.high), exp))


# visualize model fit & data
points_df <- crossing(
  copies_plus_one = 10 ** seq(0, 1.13, 0.0001),
  site = unique(bldg_df$site) 
)

points_df |> 
  mutate(   
    pred = predict(
      type = 'response',
      object = bldg_model, 
      newdata = points_df
    )) |> 
  ggplot(aes(copies_plus_one, pred, color = site)) +
  geom_smooth(
    se = F, linewidth = 0.25, alpha = 1,
    method = 'gam',
     formula = y ~ s(x, bs = "cs")
    ) + 
  geom_jitter(data = bldg_df,
              alpha = 0.75, shape = 1, size = 0.85,
              width = 0.01, height = 0.01,
              aes(copies_plus_one, cases)) +
  labs(x = 'Swab: copies+1', y = 'Cases', color = 'Site') +
  scale_x_log10()

broom.mixed::tidy(bldg_model, 'ran_vals', 
                  conf.int = T, 
                  conf.level = 0.95) |> 
  mutate(across(c(estimate, conf.low, conf.high), exp)) |> 
  ggplot(aes(y = level,
             x = estimate, 
             xmin = conf.low, 
             xmax = conf.high)) +
  geom_pointrange() +
  scale_x_log10()
```


```{r}
lst(
  term = bldg_model_summary |> 
    filter(term == "log10(copies_plus_one)"),
  IR = term$estimate |> round(0),
  IR_LO = term$conf.low |> round(0),
  IR_HI = term$conf.high |> round(0),
  VAR  = bldg_model_summary |> 
    filter(term == "sd__(Intercept)") |> 
    pluck('estimate') |> round(2),
  ints = bldg_model_intercepts,
  INT_MIN = ints |> pull(estimate) |>  min() |> round(2),
  INT_MAX = ints |> pull(estimate) |>  max() |> round(1)
) |> 
  glue_data(
    "
We sought to evalute surface detection of SARS-CoV-2 as a predictor of case burden at the building level. We applied a  mixed-effects Poisson regression analysis; random slopes were specified for buildings to account for repeated measurements on the same buildings. The incidence ratio relating a 10-fold increase in the number of viral copies (plus one) to the total number of reported cases was large and significant with a high level of certainty (IR = {IR}, 95% CI {IR_LO}-{IR_HI}). IRs for individual sites ranged from {INT_MIN} (LPR) to {INT_MAX} (DMS) with moderate variance among sites overall (SD = {VAR}), but differences between sites were small relative to the uncertainty on the individual estimates (table S--).")
```


### Table S..: Model summary for mixed-effects poisson regresson with viral copies as predictor.
```{r}
bldg_model_summary
```


### Table S..: Incidence rate ratios for SARS-CoV-2 cases six university buildings estimated by mixed-effects poisson regresson with viral copies as predictor.
```{r}
bldg_model_intercepts |> 
  select(level, estimate, conf.low, conf.high)
```


----

## Tables and Figures



<details>
<summary>Expand for plotting details</summary>

```{r figures, echo=TRUE}
# fig1 -----
fig1_timeline <- 
  event_dates |> 
  ggplot(aes(x = start, xend = end, y = event, yend = event)) +
  geom_segment(linewidth = 4, lineend = 'round',
               color = theme_color,
               alpha = 0.3) +
  geom_segment(linewidth = 1, lineend = 'butt',
             color = theme_color,
             alpha = 0.9) +
  geom_point(aes(x = end), color = theme_color, size = 1.6) +
  geom_point(color = theme_color, size = 1.6) +
  scale_x_study_dates() +
  labs(title = 'Timeline') +
  theme_no_x_labels() +
  theme_remove_grid()

fig1_cases <-
  cases_biweekly |>
  # adjust bar widths manually
  mutate(biweek = if_else(wday(biweek) == 5, biweek + 0.75, biweek - 0.75)) |>
  select(biweek, cases_student, cases_staff) |>
  pivot_longer(-biweek) |>
  mutate(name = str_remove(name, 'cases_') |> str_to_title()) |>
  ggplot() +
  geom_vline(
    data = tibble(x = as_date('2022-02-03')),
    aes(xintercept = x),
    lty = 2,
    color = 'gray'
  ) +
  geom_text(
    data = tibble(
      x = as_date('2022-02-05'),
      y = 18,
      label = 'End of data'
    ),
    aes(x, y, label = label),
    size = 2,
    hjust = 0
  ) +
  geom_col(
    aes(biweek, value, fill = name),
    linewidth = 0.15,
    width = 3.5,
    color = 'gray80',
    position = position_stack(),
    na.rm = T
  ) +
  labs(fill = NULL, title = 'UOttawa COVID-19 Cases') +
  scale_fill_carto_d() +
  scale_x_study_dates() +
  theme_no_x_labels() +
  theme_remove_grid() +
  theme(
    legend.position = c(0.9, 0.4),
    legend.key.size = unit(2, 'mm'),
    legend.background = element_rect(color = 'grey80')
  )

fig1_swabs <- 
  swabs_biweekly |> 
  ggplot(aes(biweek, positivity)) +
  geom_smooth(
    linewidth = 0.5, 
    alpha = 0.2, 
    fill = theme_color, 
    span = 0.4,
    method = 'loess',
    formula = 'y ~ x', 
    na.rm = T) +
  geom_point(color = theme_color, 
             alpha = 0.85, 
             shape = 1, 
             size = 1, 
             na.rm = T) +
  scale_x_study_dates() +
  labs(title = 'Swab Positivity (%)') +
  theme_no_x_labels() +
  theme_remove_grid()
  
fig1_co2 <-
  ggplot(swabs_biweekly, aes(biweek, co2_mean)) +
  geom_point(color = theme_color, shape = 1, alpha = 0.85, size = 1,
             na.rm = T) +
  geom_smooth(fill = theme_color, alpha = 0.2, linewidth = 0.5,
              na.rm = T) +
  labs(x = NULL, y = NULL, title = 'CO~2~ (ppm)') +
  scale_x_study_dates() +
  theme_no_x_labels() +
  theme_remove_grid()
  
fig1_wifi <-
  wifi_biweekly |> 
  ggplot(aes(biweek, mean)) +
  geom_smooth(span = 0.5, 
              linewidth = 0.5,
              alpha = 0.2, 
              fill = theme_color,
              na.rm = T) +
  geom_point(color = theme_color,  alpha = 0.85, shape = 1, size = 1,
             na.rm = T) +
  labs(title = "Wi-Fi Connections") +
  scale_x_study_dates() +
  theme_no_x_labels() +
  theme_remove_grid()

fig1_ott_ww <- 
  ggplot(regional_ww_daily) + 
  geom_smooth(aes(sample_date, mean), 
              method = 'loess', formula = 'y ~ x',
              span = 0.2, linewidth = 0.5, alpha = 0.2,
              na.rm = T,
              fill = theme_color) +
  geom_point(data = regional_ww_biweekly,
             aes(biweek, mean),
             na.rm = T,
             alpha = 0.85, shape = 1, size = 1,
             color = theme_color) +
  labs(x = 'Date',
       title = 'Regional Waste-Water',
       ) +
  scale_x_study_dates() +
  theme_remove_grid() +
  theme(axis.title.x = ggtext::element_markdown(lineheight = 1),
        axis.text.x = ggtext::element_markdown(size = 6.7)) 

figure_1 <- wrap_plots(
    fig1_timeline, 
    fig1_cases, 
    fig1_swabs, 
    fig1_co2, 
    fig1_wifi, 
    fig1_ott_ww # this is regional ww
  ) +
  plot_layout(ncol = 1, nrow = 7, heights = c(1, rep(1.5, 6)))

rm(fig1_timeline, fig1_swabs, fig1_co2, fig1_wifi, fig1_ott_ww, fig1_cases)
```


```{r figure 2, echo=TRUE}
## Figure 2: Corr heatmap -----------------------------------
figure_2 <- corrr::autoplot(corr_spearman, triangular = "lower",
                             barheight = 10) +
  geom_text(aes(label = r |> round(2)), size = 3.5)
```


```{r create fig3, echo=TRUE}
## Figure 3: Per-building res ---------------------------------

#### thematic elements and axis scales -----

# limits are based on the min/max of data to keep scales consistent across all plots of a given variable

scale_y_copies <- function() scale_y_log10(limits = c(1, 300))
scale_y_cases <- function() {
  scale_y_continuous(breaks = seq(0, 7, 3), limits = c(0,7))
}
scale_y_wifi <- function() scale_y_continuous(
  limits = c(0, 1000),
  n.breaks = 3)

scale_color_traffic <- function(){
  scale_color_carto_d(
    palette = 2,
    breaks = c('High', 'Low'),
    labels = c('High', 'Low'),
    drop = F
  )
}

theme_axes_lb_no_margin <- function(){
  theme_remove_grid() +
  theme(
    axis.title.y = element_markdown(size = 8),
    axis.text.y = element_markdown(size = 7),
    axis.line = element_line(colour = "gray30", linewidth = rel(0.5)),
    legend.title = element_markdown(size = 8),
    legend.text = element_markdown(size = 7),
    panel.border = element_blank(),
    plot.margin = margin(1,0,0,0, 'mm')
  )
}

theme_axes_lb <- function(){
  theme_remove_grid() +
  theme(
    axis.title.y = element_markdown(size = 8),
    axis.text.y = element_markdown(size = 7),
    axis.line = element_line(colour = "gray30", linewidth = rel(0.5)),
    
    legend.title = element_markdown(size = 8),
    legend.text = element_markdown(size = 7),
    panel.border = element_blank(),
    plot.margin = margin(1,2,2,2, 'mm')
  )
}

theme_axis_RES <- function(){
  theme_remove_grid() +
  theme(
    panel.border = element_blank(),
    axis.text.y = element_markdown(size = 7),
    axis.line = element_line(colour = "gray30", linewidth = rel(0.5)),
    legend.title = element_markdown(size = 8),
    legend.text = element_markdown(size = 7),
    plot.margin = margin(1,2,2,2, 'mm')
  )
}

remove_y_axis_if_not_leftmost <- function(p, site){
  if (site %in% c('FAC', 'ADM1', 'ADM2')) return(p)
  p + theme_no_y_labels()
}

geom_event <- function(site, ymin){
    geom_rect(
      data = event_dates |> mutate(site = site),
      aes(
        xmin = start, 
        xmax = end,
        ymin = ymin, 
        ymax = Inf,
        fill = event
      ),
      alpha = .25,
    )
}

scale_fill_event <- function(){
  rcartocolor::scale_fill_carto_d(palette = 'Safe',
                                  name = 'Event')
}

#### individual plot functions -----

# plot cases timeseries for site
plot_site_cases <- function(data, site){
  p <- data |>
    ggplot() +
    geom_col(
      aes(week - 1, cases),
      na.rm = T,
      linewidth = .1, alpha = 0.9,
      color = 'grey70') +
    geom_line(
      aes(week - 1, pred),
      linewidth = 1, 
      alpha = 0.5,
      color = 'blue') +
    geom_point(
      aes(week - 1, pred),
      size = 1, 
      alpha = 0.5,
      color = 'blue') +
    geom_rect(
      data = tibble(
        x = as_date('2022-02-02'), 
        xmax = as_date(Inf),
        y = 0, 
        ymax = Inf
      ),
      aes(xmin = x, 
          ymin = y, 
          xmax = xmax, 
          ymax = ymax),
      alpha = .1
      ) +
    scale_x_date_month() +
    scale_y_cases() +
    scale_fill_carto_d(
      palette = 1,  
      breaks = c('Employee', 'Student'),
      labels = c('Employee', 'Student'),
      drop = FALSE,
      name = 'Cases: Role') +
    labs(y = 'Cases', x = NULL, title = site) +
    theme_no_x_labels() +
    theme_axes_lb_no_margin()
     
  remove_y_axis_if_not_leftmost(p, site)
}

# plot swabs copies timeseries for site
plot_site_swabs <- function(data, site){
  data_early <- data |> filter(date_swab < '2022-01-01')
  data_late <- data |> filter(date_swab > '2022-01-01')
  
  p <- data_early |>
    ggplot() +
    geom_event(site, ymin = 1) +
    geom_path(
      aes(date_swab, copies_plus_one, color = traffic),
      alpha = 0.8, linewidth = 0.6) +
    geom_point(
        aes(date_swab, copies_plus_one, color = traffic),
        size = 0.6, alpha = 0.8) +
    geom_path(
      data = data_late, 
      aes(date_swab, copies_plus_one, color = traffic),
      alpha = 0.8, linewidth = 0.6) +
    geom_point(
      data = data_late, 
      aes(date_swab, copies_plus_one, color = traffic),
      size = 0.6, alpha = 0.8) +
    scale_x_date_month() +
    scale_y_copies() +
    scale_color_traffic() +
    rcartocolor::scale_fill_carto_d(palette = 'Safe') +
    labs(x = NULL, 
         y = 'Copies + 1',
         fill = 'Event',
         color = 'Traffic Level') +
    
    theme_axes_lb_no_margin() +
    theme(axis.title.y = element_markdown(),
          axis.text.x = element_markdown(size = 6),
          legend.text = element_markdown())
  
  if (site == 'RES') {
    p <- p + theme_axis_RES()
  } else {
    p <- p + theme_no_x_labels()
  }
  remove_y_axis_if_not_leftmost(p, site)
}

# plot wifi timeseries for site
plot_site_wifi <- function(data, site){
  if (is.null(data)) return(patchwork::plot_spacer())
  
  p <- data |> 
    ggplot() +
    geom_event(site, ymin = 1) +
    geom_path(
      aes(date, clients), 
      alpha = 0.5, 
      na.rm = T) +
    scale_x_date_month() +
    scale_y_wifi() +
    rcartocolor::scale_fill_carto_d(palette = 'Safe') +
    labs(y = 'Wifi', x = NULL, fill = 'Event') +
    theme_axes_lb() +
    theme(
      axis.title.y = element_markdown(),
      axis.text.x = element_markdown(size = 6))
  
  remove_y_axis_if_not_leftmost(p, site)
}


## Plot datasets ====
fig3_cases <- 
  bldg_df |> 
  mutate(pred = predict(
    bldg_model, 
    newdata = bldg_df, 
    type = 'response')
  ) |> 
  group_nest(site, .key = "cases")

fig3_swabs <- 
  swabs_tidy |> 
  mutate(
    traffic = get_traffic_level(location),
    copies = convert_cq_to_copies(pcr_ct),
    copies_plus_one = if_else(is.na(copies), 1, copies + 1)
    ) |> 
  select(site, traffic, date_swab, copies_plus_one) |>
  group_nest(site, .key = "swabs")

fig3_wifi <- 
  wifi |> 
  mutate(site = str_remove(site, 'UO_')) |> 
  select(date, site, clients) |>
  group_nest(site, .key = "wifi")

#### data handling and making building panels -----

# combine nested df
fig3_df_nest <- fig3_cases |> 
  left_join(fig3_swabs, by = join_by(site)) |> 
  left_join(fig3_wifi, by = join_by(site))

# map data to plots, combine into panel for each site
fig3_plts <- 
  fig3_df_nest |>
  mutate(site = factor(site, levels = c(
    'FAC', 'LIB', 'ADM1', 'GYM', 'ADM2', 'RES'
  ))) |> 
  arrange(site) |> 
  transmute(
    site = as.character(site),
    plt_cases = map2(cases, site, plot_site_cases),
    plt_swabs = map2(swabs, site, plot_site_swabs),
    plt_wifi = map2(wifi, site, plot_site_wifi),
  ) |> 
  mutate(panel = pmap(
    .l = list(site, plt_cases, plt_swabs, plt_wifi),
    .f = function(site,plt_cases, plt_swabs, plt_wifi) {
      p <- patchwork::wrap_plots(
        plt_cases, plt_swabs, plt_wifi, 
        ncol = 1
      ) 
      if (site == 'RES') {
        p <- p + patchwork::plot_layout(
          heights = c(1.16, 1.14, 0.63)
        )
      }
      needs_axis <- site %in% c('FAC', 'ADM1', 'ADM2')
      if (needs_axis) return(p)
      p + patchwork::plot_annotation(theme = theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank()
      ))
    }))

#### Combine all 6 sites' plots into 3*2 panel -----
(
figure_3 <- 
  patchwork::wrap_plots(
    fig3_plts$panel, 
    ncol = 2,
    tag_level = 'keep',
    guides = 'collect'
  )

)
```

</details>

### Tables


#### Summary table

```{r}
# stack summaries
swab_summary |> 
  mutate(site = 'Overall') |> 
  bind_rows(swab_summary_sites) |> 
  relocate(site) |> 
  set_names(c('Site', 'N', 'PCR-Positive', '%')) |> 
  kableExtra::kable(
    format = 'pipe',
    caption = 'Building Summary'
  )
```


#### Spearman correlation between campus-wide measures

```{r}
kableExtra::kable(
  x = corr_ci, 
  format = 'pipe',
  caption = 'Spearman r for biweekly, campus-wide measures'
  )
```

<br>

**Table 1.** Incidence Ratios from Poisson Regression Model selected by backward elimination: *Cases ~ campus-wide metrics*

```{r}
table1 <- mod_pois_main_eff_stepwise |>
  incidence_ratio_table(
    caption = 'Poisson regression model incidence ratios'
    )
table1

```


---


### Figures

```{r fig1, fig.height=6, fig.width=5.25, fig.align='left'}
(figure_1) 
```

**Figure 1**: Time-series of (top to bottom) important events at the university, proportion of PCR-positive swabs, biweekly mean ambient CO~2~ (across collection sites), biweekly mean peak number of Wi-Fi connections (across 5 buildings), biweekly mean waste-water signal (across up to 6 collection sites; relative to PPMoV), biweekly mean regional waste-water detection (relative to PPMoV). Points show biweekly means. Trend lines show the LOESS fit.

----

<br>

```{r fig2 spearman r, fig.height=4, fig.width=4, fig.align='left'}
figure_2
```

**Figure 2**. Spearman correlation between biweekly campus-wide variables: self-reported cases, floor swab positivity (Swab PCR), mean CO2, mean daily peak Wi-Fi connections, aggregate waste-water signal at the university (University WW) and regional level (Ottawa WW), 


----



--------------------------------------------------------


```{r fig3, fig.width=8, fig.height=6}
figure_3
```
**Figure 3.** Campus COVID-19 cases, swab results, CO~2~ concentrations (during swab collection), and daily peak Wi-Fi connections by building. Cases plots show counts of self-reported cases as bars and fitted values from the poisson mixed model as blue points. Case data collection was abandoned in early February 2022 (shaded area). Swabs and CO~2~ plots show results at two locations within each building, with one sample collected in a high-traffic area and the other in a low-traffic area. Swab PCR results are expressed as the number of SARS-CoV-2 RNA copies plus one, on a log-scale. Points represent the result for a single swab. Wi-fi plots show the peak daily number of simultaneous connections per building. No Wi-Fi data was available for the RES building. Shaded areas on the 'copies' and 'wifi' panels indicate university closures and study breaks.


### Supplemental

```{r save figs}
## save figures ----
# figs 1 & 3 don't work as a pdf for some reason
ggsave('fig/figure_1.png', figure_1, device = 'png', width = 7, height = 7) 
ggsave('fig/figure_2.pdf', figure_2, device = 'pdf', height = 4, width = 4)
ggsave('fig/figure_2.png', figure_2, device = 'png', height = 4, width = 4)
ggsave('fig/figure_3.png', figure_3, device = 'png', dpi = 300, height = 6, width = 6)

mapview::mapshot(figure_sites_map, file = 'fig/figure_s2_map.pdf',
                 remove_controls = T)
```

------------------------------------------------------
  
<br>
  
```{r display map, echo=FALSE}
figure_sites_map
```

**Figure S2: Map of swab collection sites.** Pink markers represent waste-water collection sites; purple markers represent buildings where surface testing was performed.



--------------------------------------------

#### CO~2~ trend 

No distinct trend in CO~2~ over time. Generally stable with few outliers.

```{r}
swabs_tidy |> 
  ggplot(aes(date_swab, co2)) + geom_point() + geom_smooth() +
  labs(x = 'Date', y = 'CO~2~ (ppm)') +
  scale_x_study_dates() +
  theme(axis.title.y = element_markdown())
```


--------------------------------------------

## Results

### Abstract Results

```{r abstract rs, results='asis', echo=F}
rs_data <- lst(
  N_SWABS = nrow(swabs_tidy),
  POS = swab_summary$positivity,
  POS_MIN = min(swab_summary_sites$positivity),
  POS_MAX = max(swab_summary_sites$positivity),
)

rs_abstract <- rs_data |> 
  glue::glue_data(
    "Over the 32-week study period, we collected {N_SWABS} swabs at six university buildings. Overall, {POS}% of swabs were PCR-positive for SARS-CoV-2, with individual buildings ranging between {POS_MIN}% and {POS_MAX}%.

*Comment on when spikes in cases, swabs, and waste-water occurred….*

*Comment on prediction of cases using swabs, ww, or combined approach…*
"
  )

cat(rs_abstract)
```

---

### Results (Body)

```{r interpolate rs, results='asis', echo=TRUE}

result_p1 <- 
  lst(
    N_CASES = total_n_cases_study_period, # 116
    corr_sc = corr_ci |> filter(terms == 'SwPCR-Cases'),
    COR_SC = corr_sc |> pluck('r') |> round(2), # 0.7
    corr_r_lo = corr_sc |> pluck('lower') |> round(2),
    corr_r_hi = corr_sc |> pluck('upper') |> round(2),
    COR_SC_CI = str_glue('{corr_r_lo}-{corr_r_hi}'),
    corr_sr = corr_ci |> filter(terms == 'SwPCR-OttWW'),
    COR_SR = corr_sr |> pluck('r') |> round(2), # 0.7
    corr_r_lo = corr_sr |> pluck('lower') |> round(2),
    corr_r_hi = corr_sr |> pluck('upper') |> round(2),
    COR_SR_CI = str_glue('{corr_r_lo}-{corr_r_hi}'),
    # corr_sw = corr_ci |> filter(terms == 'SwPCR-UnvWW'),
    # COR_SW = corr_sw |> pluck('r') |> round(2), # 0.7
    # corr_r_lo = corr_sw |> pluck('lower') |> round(2),
    # corr_r_hi = corr_sw |> pluck('upper') |> round(2),
    # COR_SW_CI = str_glue('{corr_r_lo}-{corr_r_hi}'),
  ) |> 
  glue::glue_data("
#### Detection of SARS-CoV-2 from floor swabs and wastewater across campus

From September 2021 to April 2022, we conducted environmental surveillance of SARS-CoV-2 across the University of Ottawa campus using both built environment swabbing and wastewater testing. Floor swabs were collected twice weekly from six buildings on the main campus, including a residence hall, the main library, and lecture and administration buildings. The floors of two sites within each building were sampled, a high-traffic site close to the main entrance, and a low-traffic site at a more remote location within the building. Wastewater was collected from six sites across the main campus over the study period, however only one site (TBT) had concurrent surface swabbing (Fig. S1). SARS-CoV-2 RNA was detected from built environment and wastewater samples according to established protocols (see Methods) (refs).  
  
There were {N_CASES} reported cases of COVID-19 among students and staff on campus during the study period, with case reporting ceased in February 2022. Low numbers of cases were reported in the fall term, and the highest numbers reported in January, coinciding with a campus-wide closure in response to the Omicron variant (Fig. 1). The aggregate environmental surveillance trends broadly paralleled case incidence, with low SARS-CoV-2 detection during the fall term (September to December) and spikes in both floor swab positivity and university wastewater signal in January. A decline after the January peak preceded a second increase in environmental SARS-CoV-2 signal observed in late March (Fig. S1). These university case and environmental detection trends correspond with two increases in COVID-19 prevalence reported in Ottawa city-wide wastewater data.

We observed positive correlations between university cases, swab positivity, university wastewater signal, and Ottawa wastewater signal (Fig. 2). The strongest correlations were between cases and swab positivity (Spearman r = {COR_SC}, 95% CI: {COR_SC_CI}) and Ottawa wastewater and swab positivity (Spearman r = {COR_SR}, 95% CI: {COR_SR_CI}). These results suggest that built environment and wastewater surveillance methods could serve as predictors for estimating active campus cases and that environmental detection of SARS-CoV-2 at the university paralleled city-wide trends.")
 # We found a significant correlation between swab positivity and wastewater signal (Spearman r = {COR_SW}, 95% CI: {COR_SW_CI}). The signal increases occurred after the local introduction of the Omicron variant and correspond with two city-wide peaks in COVID-19 prevalence reported in Ottawa wastewater and case data.


result_p2 <- lst(
  MED_CO2 = median(swabs_tidy$co2, na.rm = T) |> round(),
  RANGE_CO2 = range(swabs_tidy$co2) |> 
    paste0(collapse = ' - ')
) |> 
  glue::glue_data("
#### Building occupancy measures such as Wi-Fi usage and CO~2~ levels did not track with case levels or built environment detection.
    
The risk of COVID-19 transmission is increased in congregate settings and in buildings with poor ventilation (ref). Therefore, variation in case levels between buildings might reflect differences in building occupancy or ventilation. We used two proxy measures, CO~2~ levels and Wi-Fi usage, to estimate building occupancy or (in the case of CO~2~) poor air ventilation. CO~2~ was measured concurrently with the floor swabbing at each sampling site, while daily building-level Wi-fi usage was shared by the university. CO~2~ concentrations were remarkably stable across buildings and time, at levels indicating high indoor air quality (median: {MED_CO2} ppm, range: {RANGE_CO2} ppm). Wi-fi usage, on the other hand, fluctuated during the term, with expected drops during reading week, winter break, and individual building closures (Figs. 1, 3). Neither measure of building occupancy, however, were significantly correlated with campus COVID-19 cases or floor swab detection during the study period (Fig. 2).
")

result_p3 <- lst(
  mod_sum = mod_pois_main_eff_stepwise |> 
    broom::tidy(exponentiate = T, conf.int = T),
  disp_test = AER::dispersiontest(mod_pois_main_eff_stepwise),
  DISP_EST = disp_test$estimate |> round(2),
  DISP_P = ifelse(disp_test$p.value > 0.05, ' > 0.05', '≤ 0.05')
) |> 
  glue::glue_data("
#### Modeling of campus-wide cases based on environmental detection

Non-invasive approaches to monitoring SARS-CoV-2 levels such as environmental sampling are valuable when systematic testing of individuals is unfeasible. We evaluated predictors of the campus-wide case burden using Poisson regression models selected by backward elimination. Predictors specified in the full model included surface swab positivity (across 6 buildings), CO~2~ concentrations (at the time of swab collection), regional waste-water signal, and Wi-Fi user counts. Backward elimination dropped the CO~2~ term and indicated the remaining variables as significant, positive predictors of case counts. The regional waste-water signal had the largest estimated effect, followed by peak Wi-Fi users, swab positivity, and university waste-water (Table 1). The selected model did not violate the assumption of equidispersion (dispersion = {DISP_EST}, *p* {DISP_P}). Regional wastewater did show a moderate collinearity with the other predictors (vif = VIF_WW)."
)

# hi-low traffic effect paragraph
result_p4 <- lst(
  df = swab_summary_location_traffic |> mutate(p = positivity),
  mod = traffic_model |> filter(term == 'traffichigh'),
  high_n = df |> filter(traffic == 'high traffic') |> pull(n),
  high_p = df |> filter(traffic == 'high traffic') |> pull(p),
  hi_str = paste0(high_p, '%, N=', high_n),
  low_n = df |> filter(traffic == 'low traffic') |> pull(n),
  low_p = df |> filter(traffic == 'low traffic') |> pull(p),
  low_str = paste0(low_p, '%, N=', low_n),
  odds = mod |> pull(estimate) |> round(2),
  ci_lo = mod |> pull(conf.low) |> round(2),
  ci_hi = mod |> pull(conf.high) |> round(2),
  odds_str = str_glue('OR = {odds}, 95% CI {ci_lo}, {ci_hi}'),
) |> 
  glue::glue_data(
"
#### Surface detection of SARS-CoV-2 was not greater in high-traffic areas

At each building where environmental surveillance by surface swabbing was performed, we selected one high-traffic area where people often travel or congregate and a second low-traffic area for contrast. We hypothesized that the floors in commonly frequented locations would have greater rates of SARS-CoV-2 detection. However, positivity rates were similar across high-traffic ({hi_str}) and low-traffic sites ({low_str}). To confirm this, we fit a mixed-effects logistic regression model, with the surface swab result as a binary outcome, the traffic level as a fixed effect, and specified random intercepts for each building to account for the clustering of sites. This model indicated that higher-traffic locations did not have significantly greater positivity rates than low-traffic locations ({odds_str})."
)
```


```{r, results='asis', echo=FALSE}
print(result_p1)
```


```{r, results='asis', echo=FALSE}
print(result_p2)
```


```{r, results='asis', echo=FALSE}
print(result_p3)
```

```{r, results='asis', echo=FALSE}
print(result_p4)
```



--------------------------------------------

## Case Data Imputation...

Multiple imputation (mice) has a key assumption that data is MAR. But data is (arguably) not MAR, but because of some dynamics not measured in the data (like the university giving up hope on recording the data in 2022).

Using `mice` means making the analysis *much* more complicated... Generally, you need to model each imputed dataset and then analyze the pooled results. That gets a lot more complicated when needing to first aggregate the data, join to a bunch of other data, do various modelling tasks.... all nested within each iteration.

**Instead, I used a simpler ad-hoc method:**

  - if positive-test-result date is available, use that, else:
  - use -5 days from end-of-isolation date, or if not available,
  - use +3 days from symptoms-began date

--------------------------------------------

<details>

<summary>R Software details</summary>

- Statistical analysis was performed using  R version 4.2.2 (2022-10-31; cite Ihaka & Gentleman).

- Generalized linear models were created using the `glm` function. Mixed models were created using the `glmer` function from the package `lme4` (Bates et al.).

- We fit poisson regression models with the number of campus-wide cases as the outcome; we applied backwards selection to evaluate predictors of campus-wide cases, including the aggregated results (means) of surface swabbing, waste-water testing, CO2 monitors, and Wi-Fi user counts.

- We used mixed effects logistic regression to model the presence of SARS-CoV-2 infected individuals as a binary outcome (ie. positive event: one or more cases occurring during a week) in a university building, using surface swab PCR results as predictor with random intercepts for buildings.

- Graphics were created with ggplot2 (v3.4.1)

- Find our analysis code at our public github repository: https://github.com/CUBE-Ontario/UOttawa-Analysis


```{r}
sessionInfo()
```

</details>

```{r}

```

